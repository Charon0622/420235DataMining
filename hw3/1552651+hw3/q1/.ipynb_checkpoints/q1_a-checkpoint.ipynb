{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import math\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import time, datetime\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 左下角经纬度坐标\n",
    "lb_lon = 121.20120490000001\n",
    "lb_lat = 31.28175691\n",
    "\n",
    "# 上角经纬度坐标\n",
    "rt_lon = 121.2183295\n",
    "rt_lat = 31.29339344\n",
    "\n",
    "# 栅格边长（左下角栅格坐标为 (0, 0) ）\n",
    "grid_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据两点经纬度计算两点间距离\n",
    "def haversine(lon1, lat1, lon2, lat2): # 经度1，纬度1，经度2，纬度2 （十进制度数）  \n",
    "    \"\"\" \n",
    "    Calculate the great circle distance between two points  \n",
    "    on the earth (specified in decimal degrees) \n",
    "    \"\"\"  \n",
    "    # 将十进制度数转化为弧度  \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])  \n",
    "  \n",
    "    # haversine公式  \n",
    "    dlon = lon2 - lon1   \n",
    "    dlat = lat2 - lat1   \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2  \n",
    "    c = 2 * asin(sqrt(a))   \n",
    "    r = 6371 # 地球平均半径，单位为公里  \n",
    "    return c * r * 1000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 横向最大距离\n",
    "max_distance_x =  haversine(lb_lon, lb_lat, rt_lon, lb_lat)\n",
    "# 右上角栅格横坐标\n",
    "int(max_distance_x / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 纵向最大距离\n",
    "max_distance_y = haversine(lb_lon, lb_lat, lb_lon, rt_lat)\n",
    "# 右上角栅格纵坐标\n",
    "int(max_distance_y / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将地图栅格化，将经纬度坐标转化为栅格坐标，左下角的栅格坐标是 (0, 0) ，右上角的栅格坐标是 (81, 64)\n",
    "# 再将栅格坐标转化为栅格ID（0 ～ 82 * 65 - 1 = 5329）共 5330 个栅格，左下角的栅格ID是 0 ，右上角的栅格ID是 5329\n",
    "def ll_to_gridID(lon, lat):\n",
    "    # 左下角经纬度坐标，栅格边长\n",
    "    global lb_lon, lb_lat, grid_len\n",
    "    \n",
    "    # 将经纬度坐标转化为栅格坐标\n",
    "    X = int(haversine(lon, lb_lat, lb_lon, lb_lat) / grid_len) \n",
    "    Y = int(haversine(lb_lon, lat, lb_lon, lb_lat) / grid_len)\n",
    "    \n",
    "    # 将栅格坐标转化为栅格ID：gridID = X + Y * 82\n",
    "    gridID = X + Y * 82\n",
    "    \n",
    "    return (gridID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将栅格ID转化为栅格中心经纬度\n",
    "def gridID_to_ll(gridID):\n",
    "    # 左下角经纬度坐标，右上角经纬度坐标，栅格边长\n",
    "    global lb_lon, lb_lat, rt_lon, rt_lat\n",
    "    \n",
    "    # 将栅格ID转化为栅格坐标\n",
    "    X = gridID % 82\n",
    "    Y = int(gridID / 82)\n",
    "    \n",
    "    # 将栅格坐标转化为经纬度坐标\n",
    "    # 栅格的边和栅格的中心位置将横向长度划分为 82 * 2 = 164 份\n",
    "    # 栅格的边和栅格的中心位置将纵向长度划分为 65 * 2 = 130 份\n",
    "    # 每一份的经度差：\n",
    "    delta_lon = (rt_lon - lb_lon) / 164\n",
    "    # 每一份的纬度差：\n",
    "    delta_lat = (rt_lat - lb_lat) / 130\n",
    "    # 栅格坐标横坐标为X的栅格的中心点经度：\n",
    "    lon = lb_lon + (1 + 2 * X) * delta_lon\n",
    "    # 栅格坐标纵坐标为Y的栅格的中心点经度：\n",
    "    lat = lb_lat + (1 + 2 * Y) * delta_lat\n",
    "    \n",
    "    return [lon, lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并两张表，用 data_2g 中的 RNCID_1，CellID_1 与 gongcan_2g 的 RNCID，CellID 匹配，将基站的经纬度信息加到 data_2g 中\n",
    "def merge_data_gongcan():\n",
    "    data_2g = pd.read_csv('../raw_data/data_2g.csv')\n",
    "    gongcan_2g = pd.read_csv('../raw_data/2g_gongcan.csv')\n",
    "    \n",
    "    for i in range(1, 8):\n",
    "        # 换掉 gongcan_2g 的列名用以和 data_2g merge\n",
    "        gongcan_2g.columns = ['RNCID_' + str(i), 'CellID_' + str(i), 'Lat_' + str(i), 'Lon_' + str(i)]    \n",
    "        data_2g = pd.merge(data_2g, gongcan_2g, how='left', on=['RNCID_' + str(i), 'CellID_' + str(i)])\n",
    "        \n",
    "    # 将 RSSI_1 ~ RSSI_7 的空缺值nan用 -sys.maxsize - 1 来代替\n",
    "    for j in range(1, 8):\n",
    "        data_2g['RSSI_' + str(j)] = data_2g['RSSI_' + str(j)].fillna(-sys.maxsize - 1)\n",
    "    \n",
    "    # 将其余空缺值nan替换为-1\n",
    "    data_2g = data_2g.fillna(-1)\n",
    "    return data_2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据MR数据的GPS加上栅格ID\n",
    "def add_gridID(data):\n",
    "    data['GridID'] = data.apply(lambda x: ll_to_gridID(x.Longitude, x.Latitude), axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机选取80%的数据记录作为训练集，余下20%作为测试集合\n",
    "def data_train_test_split(data, random_seed):\n",
    "    # 样本特征集（将 DataFrame 转化为 list）\n",
    "    # 选取的特征包括 有效连接的基站数，7个基站的经纬度及相应的RSSI值 共22个特征\n",
    "    X = data[['Lon_1', 'Lat_1', 'RSSI_1', \n",
    "              'Lon_2', 'Lat_2', 'RSSI_2', \n",
    "              'Lon_3', 'Lat_3', 'RSSI_3', \n",
    "              'Lon_4', 'Lat_4', 'RSSI_4',\n",
    "              'Lon_5', 'Lat_5', 'RSSI_5',\n",
    "              'Lon_6', 'Lat_6', 'RSSI_6',\n",
    "              'Lon_7', 'Lat_7', 'RSSI_7',\n",
    "              'Num_connected'\n",
    "             ]].values\n",
    "    # 样本结果（将 DataFrame 转化为 list ）\n",
    "    y = data['GridID'].values\n",
    "    \n",
    "    # 随机选取80%的数据记录作为训练集，余下20%作为测试集合\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传入不同的分类器，训练并且作出预测\n",
    "def train_classifier_and_predict(classifier_model, X_train, X_test, y_train):\n",
    "    clf = classifier_model\n",
    "    y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算预测位置和证实位置的误差（采用欧式距离），按照计算误差从小到大进行排序\n",
    "# 返回小到大进行排序的误差\n",
    "def calculate_error_and_sort(y_pred, y_test):\n",
    "    \n",
    "    # 将预测结果里的栅格ID转化为经纬度坐标\n",
    "    y_pred = list(map(gridID_to_ll, y_pred))\n",
    "    # 将测试结果里的栅格ID转化为经纬度坐标\n",
    "    y_test = list(map(gridID_to_ll, y_test))\n",
    "    \n",
    "    # 将预测结果和测试结果的经纬度坐标放在同一个list里，形成一个二维数组\n",
    "    temp = [y_pred[i] + y_test[i] for i in range(min(len(y_pred),len(y_test)))]\n",
    "    \n",
    "    # 计算各个误差\n",
    "    errors = [haversine(x[0], x[1], x[2], x[3]) for x in temp]\n",
    "    # 按照计算误差从小到大进行排序\n",
    "    sorted_errors = sorted(errors)\n",
    "    \n",
    "    return sorted_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算10次误差的平均值（即平均误差）\n",
    "def calculate_avg_errors(errors_list):\n",
    "    errors_avg = []\n",
    "    for i in range(len(errors_list[0])):\n",
    "        errors_avg.append(np.mean([x[i] for x in errors_list]))\n",
    "    return  errors_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 precision，recall 和 f-measurement，对模型进行评价\n",
    "def evaluate(y_pred, y_test):\n",
    "    \n",
    "    evaluations = {}\n",
    "    \n",
    "    # precision for each\n",
    "    precision_foreach = precision_score(y_test, y_pred, average=None)\n",
    "    evaluations['precision foreach'] = precision_foreach\n",
    "    # precision overall\n",
    "    precision_overall = precision_score(y_test, y_pred, average='macro')\n",
    "    evaluations['precision overall'] = precision_overall\n",
    "    # recall for each\n",
    "    recall_foreach = recall_score(y_test, y_pred, average=None)\n",
    "    evaluations['recall foreach'] = recall_foreach\n",
    "    # recall overall\n",
    "    recall_overall = recall_score(y_test, y_pred, average='macro')\n",
    "    evaluations['recall overall'] = recall_overall\n",
    "    # f-measurement for each\n",
    "    f_measurement_foreach = f1_score(y_test, y_pred, average=None)\n",
    "    evaluations['f-measurement foreach'] = f_measurement_foreach\n",
    "    # f-measurement overall\n",
    "    f_measurement_overall = f1_score(y_test, y_pred, average='macro')\n",
    "    evaluations['f-measurement overall'] = f_measurement_overall\n",
    "    \n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 调用前面的函数，传入分类器，返回10次预测结果和平均误差\n",
    "def get_result(classifier_model, data):\n",
    "    \n",
    "    # 用以存储10次预测结果\n",
    "    y_pred_list = []\n",
    "    # 用以存储10次误差\n",
    "    errors_list = []\n",
    "    # 用以存储10次训练时间\n",
    "    time_list = []\n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        # 随机选取80%的数据记录作为训练集，余下20%作为测试集合，传入i作为random_seed\n",
    "        X_train, X_test, y_train, y_test = data_train_test_split(data, i)\n",
    "        # 训练并且作出预测\n",
    "        start = time.clock()\n",
    "        y_pred = train_classifier_and_predict(classifier_model, X_train, X_test, y_train)\n",
    "        end  = time.clock()\n",
    "        delta_time = end - start\n",
    "        time_list.append(delta_time)\n",
    "        # 存储本次预测结果\n",
    "        y_pred_list.append(list(y_pred))\n",
    "        # 计算预测位置和证实位置的误差（采用欧式距离），按照计算误差从小到大进行排序\n",
    "        errors = calculate_error_and_sort(y_pred, y_test)\n",
    "        # 存储本次误差排序\n",
    "        errors_list.append(errors)\n",
    "        \n",
    "    # 计算10次误差的平均值\n",
    "    avg_errors = calculate_avg_errors(errors_list)\n",
    "    \n",
    "    # 找出0%, 10%，20%，30%，40%，50%，60%，70%，80%，90%，100%处的点\n",
    "    lens = len(avg_errors)\n",
    "    percents = np.arange(0.1, 1.1, 0.1)\n",
    "    errors = []\n",
    "    errors.append(avg_errors[0])\n",
    "    for i in percents:\n",
    "        errors.append(avg_errors[int(lens * i) - 1])\n",
    "    \n",
    "    # 计算 precision，recall 和 f-measurement\n",
    "    evaluations = evaluate(y_pred, y_test)\n",
    "    \n",
    "    # 计算平均时间\n",
    "    avg_time = np.array(time_list).mean()\n",
    "    \n",
    "    # 返回10次预测结果，平均误差，评价指标和平均时间\n",
    "    return y_pred_list, errors, evaluations, avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制平均误差概率分布图\n",
    "def error_plot(classifier_models, model_errors):\n",
    "    plt.style.use('ggplot')\n",
    "    markers = ['v', '^', 'o', '+', '*', 'D', 'p', 's', 'x']\n",
    "\n",
    "    xticks = np.arange(0, 1.1, 0.1)\n",
    "    plt.xticks(xticks)\n",
    "    for clf_name, marker in zip(classifier_models.keys(), markers):\n",
    "        plt.plot(xticks, model_errors[clf_name],\n",
    "                 linestyle='--', marker=marker, alpha=0.8)\n",
    "\n",
    "    plt.title('Comparison of Classifiers')\n",
    "    plt.xlabel('CDF')\n",
    "    plt.ylabel('Error (meters)')\n",
    "    plt.legend(classifier_models.keys())\n",
    "    plt.savefig('Error_of_Models.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制 precision，recall 和 f-measurement 图\n",
    "def evaluations_plot(classifier_models, model_evaluations):\n",
    "    plt.style.use('ggplot')\n",
    "    xticks = np.arange(len(classifier_models))\n",
    "    plt.xticks(xticks, classifier_models.keys(), rotation=20)\n",
    "    markers = ['v', '+', 'o']\n",
    "\n",
    "    evaluations = []\n",
    "\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f_measurement = []\n",
    "    for key0 in model_evaluations:\n",
    "        for key1 in model_evaluations[key0]:\n",
    "            if key1 == 'precision overall':\n",
    "                precision.append(model_evaluations[key0][key1])\n",
    "            elif key1 == 'recall overall':\n",
    "                recall.append(model_evaluations[key0][key1])\n",
    "            elif key1 == 'f-measurement overall':\n",
    "                f_measurement.append(model_evaluations[key0][key1])\n",
    "    evaluations = [precision, recall, f_measurement]\n",
    "\n",
    "    for evaluation, marker in zip(evaluations, markers):\n",
    "        plt.plot(xticks, evaluation,\n",
    "                 linestyle='--', marker=marker, alpha=0.8)\n",
    "\n",
    "    plt.title('Evaluation of Models')\n",
    "    plt.xlabel('Model Names')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend(['precision overall', 'recall overall', 'f-measurement overall'])\n",
    "    plt.savefig('Evaluation_of_Models.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制时间图\n",
    "def time_plot(classifier_models, model_times):\n",
    "    plt.style.use('ggplot')\n",
    "    xticks = np.arange(len(classifier_models))\n",
    "    plt.xticks(xticks, classifier_models.keys(), rotation=20)\n",
    "    plt.plot(xticks, list(model_times.values()), marker='o', linestyle='--', alpha=0.8)\n",
    "\n",
    "    plt.title('Time of Models')\n",
    "    plt.xlabel('Model Names')\n",
    "    plt.ylabel('Time')\n",
    "    plt.savefig('Time_of_Models.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a():\n",
    "    # 合并两张表\n",
    "    data = merge_data_gongcan()\n",
    "    \n",
    "    # 根据MR数据的GPS换算成栅格ID作为结果\n",
    "    data = add_gridID(data)\n",
    "    \n",
    "    # 7个分类器\n",
    "    classifier_models = {\n",
    "        # 高斯朴素贝叶斯分类器 Gaussian Naive Bayes (GaussianNB)\n",
    "        'GaussianNB': GaussianNB(),\n",
    "        # K近邻分类器 KNeighborsClassifier\n",
    "        'KNeighbors': KNeighborsClassifier(n_neighbors=2),\n",
    "        # 决策树分类器 DecisionTreeClassifier\n",
    "        'DecisionTree': tree.DecisionTreeClassifier(criterion='entropy', max_depth=50),\n",
    "        # 随机森林 RandomForestClassifier\n",
    "        'RandomForest': RandomForestClassifier(max_depth=3, n_estimators=45),\n",
    "        # AdaBoost AdaBoostClassifier\n",
    "        'AdaBoost': AdaBoostClassifier(n_estimators=150, learning_rate = 0.1),\n",
    "        # Bagging meta-estimator（Bagging 元估计器）BaggingClassifier\n",
    "        'Bagging': BaggingClassifier(n_estimators=40),\n",
    "        # GBDT（梯度树提升）GradientBoostingClassifier\n",
    "        'GradientBoosting': GradientBoostingClassifier(n_estimators=40, max_depth=10)\n",
    "}\n",
    "    \n",
    "    # 用以存储10次真实结果\n",
    "    y_test_list = []\n",
    "    \n",
    "    # 得到10次真实结果\n",
    "    for i in range(0, 10):\n",
    "        X_train, X_test, y_train, y_test = data_train_test_split(data, i)\n",
    "        y_test_list.append(list(y_test))\n",
    "     \n",
    "    # 存储模型的10次预测结果\n",
    "    model_preds = {}\n",
    "    # 存储模型的10次平均误差\n",
    "    model_errors = {}\n",
    "    # 存储模型的评价\n",
    "    model_evaluations = {}\n",
    "    # 存储模型训练时间\n",
    "    model_times = {}\n",
    "    \n",
    "    # 获得每种分类器的10次预测结果\n",
    "    for key in classifier_models:\n",
    "        y_pred_list, avg_errors, evaluations, avg_time = get_result(classifier_models[key], data)\n",
    "        model_preds[key] = y_pred_list\n",
    "        model_errors[key] = avg_errors\n",
    "        model_evaluations[key] = evaluations\n",
    "        model_times[key] = avg_time\n",
    "    \n",
    "    # 绘制平均误差概率分布图\n",
    "    error_plot(classifier_models, model_errors)\n",
    "    # 绘制 precision，recall 和 f-measurement 图\n",
    "    evaluations_plot(classifier_models, model_evaluations)\n",
    "    # 绘制时间图\n",
    "    time_plot(classifier_models, model_times)\n",
    "        \n",
    "    return  y_test_list, model_preds, model_errors, model_evaluations, model_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-cf4e0164f694>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_evaluations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-124e7e8de55f>\u001b[0m in \u001b[0;36ma\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# 获得每种分类器的10次预测结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifier_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0my_pred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mmodel_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mmodel_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4433308d04fc>\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(classifier_model, data)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# 训练并且作出预测\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_classifier_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mend\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdelta_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-5fd3ba360591>\u001b[0m in \u001b[0;36mtrain_classifier_and_predict\u001b[0;34m(classifier_model, X_train, X_test, y_train)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_classifier_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             residual = loss.negative_gradient(y, y_pred, k=k,\n\u001b[0;32m--> 762\u001b[0;31m                                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;31m# induce regression tree on residuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mnegative_gradient\u001b[0;34m(self, y, pred, k, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;34m\"\"\"Compute negative gradient for the ``k``-th class. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         return y - np.nan_to_num(np.exp(pred[:, k] -\n\u001b[0;32m--> 562\u001b[0;31m                                         logsumexp(pred, axis=1)))\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# suppress warnings about log of zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_test_list, model_preds, model_errors, model_evaluations, model_times = a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间戳转换函数\n",
    "def timeStamp_to_time(timeStamp):\n",
    "    timeArray = time.localtime(timeStamp)\n",
    "    otherStyleTime = time.strftime(\"%Y--%m--%d %H:%M:%S\", timeArray)\n",
    "    return otherStyleTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b():\n",
    "     # 合并两张表\n",
    "    data = merge_data_gongcan()\n",
    "    \n",
    "    # 根据MR数据的GPS换算成栅格ID作为结果\n",
    "    data = add_gridID(data)\n",
    "    \n",
    "    # 数据中IMSI只有 460012796993062，460011670515939，460016291512177 三个值，将他们分开\n",
    "    ID1 = 460012796993062.00,\n",
    "    ID2 = 460011670515939.06,\n",
    "    ID3 = 460016291512176.94\n",
    "    data_1 = data[data['IMSI'] == ID1].sort_values(by='MRTime')  \n",
    "    data_2 = data[data['IMSI'] == ID2].sort_values(by='MRTime')  \n",
    "    data_3 = data[data['IMSI'] == ID3].sort_values(by='MRTime')  \n",
    "    \n",
    "    return data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_2 = data_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算出两行间的时间差和距离\n",
    "time = []\n",
    "dis = []\n",
    "for i in range(len(data_2) - 1):\n",
    "    time.append((data_2.MRTime[i + 1] - data_2.MRTime[i]) / 1000)\n",
    "    dis.append(haversine(data_2.Longitude[i], data_2.Latitude[i], data_2.Longitude[i + 1], data_2.Latitude[i + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculte_v(time, dis):\n",
    "    return dis / time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = map(calculte_v, zip(dis, time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "map"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "calculte_v() missing 1 required positional argument: 'dis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-a1cf8096d5b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: calculte_v() missing 1 required positional argument: 'dis'"
     ]
    }
   ],
   "source": [
    "list(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-172-74c9c187d59c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-172-74c9c187d59c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print key\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "for key, value in v:\n",
    "    print key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
